{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "import pandas as pd \n",
    "import json\n",
    "from flask import request, jsonify\n",
    "from flask import Flask, Blueprint\n",
    "from flask import render_template\n",
    "\n",
    "import pickle\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hello = Blueprint('hello', __name__)\n",
    "\n",
    "@hello.route('/')\n",
    "def index():\n",
    "    #return 'Flask default function - logreg'\n",
    "    return render_template(\"index.html\")\n",
    "\n",
    "@hello.route('/hi')\n",
    "def goodbye():\n",
    "    return 'Hey Hello World!'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pickle.load(open('logreg.pickle', 'rb' ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Scaler from pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('scaler.pickle', 'rb') as f2:\n",
    "    scaler_pkl = pickle.load(f2)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Encoder from pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('encoder.pickle', 'rb') as f3:\n",
    "    encoder_pkl = pickle.load(f3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert an array to a dataframe\n",
    "def convert_to_df(arr):\n",
    "    column_names = ['Administrative', 'ProductRelated_Duration', 'BounceRates', 'PageValues', 'SpecialDay', 'Month']\n",
    "    # Create a DataFrame\n",
    "    df = pd.DataFrame([arr], columns=column_names)\n",
    "    df = df.astype(float)\n",
    "\n",
    "    return df\n",
    "\n",
    "#This function encodes the 'SpecialDay', 'Month' in the dataframe using the pickled encoder and returns the modified dataframe\n",
    "def one_hot_encoding(df):\n",
    "    encoded_data = encoder_pkl.transform(df[['SpecialDay', 'Month']])\n",
    "    # Convert the encoded data to a DataFrame with meaningful column names\n",
    "    encoded_df = pd.DataFrame(\n",
    "        encoded_data,\n",
    "        columns=[f\"{col}_{val}\" for col, vals in zip(['SpecialDay', 'Month'], encoder_pkl.categories_) for val in vals]\n",
    "    )\n",
    "\n",
    "    # Concatenate the original DataFrame with the encoded DataFrame\n",
    "    encoded_data2 = pd.concat([df, encoded_df], axis=1)\n",
    "\n",
    "    # Drop the original columns that were encoded\n",
    "    encoded_data2 = encoded_data2.drop(['SpecialDay', 'Month'], axis=1)\n",
    "    return encoded_data2\n",
    "\n",
    "#This function scales the data in a dataframe using the pickled scaler\n",
    "def scale_input_data(df):\n",
    "    input_scaled = scaler_pkl.transform(df)\n",
    "    return input_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Endpoint to serve incoming requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@hello.route('/api', methods=['GET'])\n",
    "def api():\n",
    "    field1 = request.args.get('field1')\n",
    "    field2 = request.args.get('field2')\n",
    "    field3 = request.args.get('field3')\n",
    "    field4 = request.args.get('field4')\n",
    "    field5 = request.args.get('field5')\n",
    "    field6 = request.args.get('field6')\n",
    "    \n",
    "    # For example, print data to the console\n",
    "    \n",
    "    input_arr=[field1, field2, field3, field4, field5, field6]\n",
    "    print(f\"Input data: {input_arr}\")\n",
    "    print(\" \")\n",
    "    \n",
    "    input_df = convert_to_df(input_arr)\n",
    "    one_hot_encoded_df = one_hot_encoding(input_df)\n",
    "    \n",
    "    ##----only for printing purpose-----------------------\n",
    "    array_as_list = one_hot_encoded_df.values.flatten().tolist()\n",
    "    formatted_string = ', '.join(map(str, array_as_list))\n",
    "    print(f\"Encoded data: [{formatted_string}]\")\n",
    "    print(\" \")\n",
    "    #-----------------------------------------------------\n",
    "    \n",
    "    input_scaled=scale_input_data(one_hot_encoded_df)\n",
    "    \n",
    "    ##----only for printing purpose-----------------------\n",
    "    array_as_list2 = input_scaled.flatten().tolist()\n",
    "    rounded_list = [round(element, 2) for element in array_as_list2]\n",
    "    formatted_string2 = ', '.join(map(str, rounded_list))\n",
    "    print(f\"Scaled data: [{formatted_string2}]\")\n",
    "    print(\" \")\n",
    "    #-----------------------------------------------------\n",
    "    \n",
    "    \n",
    "    y_pred = model.predict(input_scaled)\n",
    "    #print(y_pred[0])\n",
    "\n",
    "    y_prob = model.predict_proba(input_scaled)\n",
    "    y_prob = np.round(y_prob, 3)\n",
    "    #print(y_prob[0])\n",
    "\n",
    "    # Create a dictionary\n",
    "    result_dict = {\n",
    "        \"predicted_class\": y_pred.tolist(),\n",
    "        \"probabilities\": y_prob.tolist()\n",
    "    }\n",
    "    \n",
    "    print(f\"Model Inference Results: [{result_dict}]\")\n",
    "    # Convert the dictionary to JSON\n",
    "    json_data = json.dumps(result_dict)\n",
    "\n",
    "    return json_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:5500\n",
      " * Running on http://192.168.1.5:5500\n",
      "Press CTRL+C to quit\n",
      "192.168.1.5 - - [05/Feb/2024 22:37:47] \"GET / HTTP/1.1\" 200 -\n",
      "192.168.1.5 - - [05/Feb/2024 22:37:48] \"GET /favicon.ico HTTP/1.1\" 404 -\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    app = Flask(__name__)\n",
    "    app.register_blueprint(hello, url_prefix='/')\n",
    "\n",
    "    app.run(host='0.0.0.0', port=5500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "practice_exercise_solutions_week2_cv_aiml_online.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "7ff011b2994a81687ed3f4982f21bb61ff5447a6a94217a4bd0912dbb40f24ee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
